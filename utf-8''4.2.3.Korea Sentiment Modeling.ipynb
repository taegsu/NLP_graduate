{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nfrom datetime import datetime\nimport tensorflow as tf\nimport numpy as np\nimport json\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "DATA_IN_PATH = './data/'\nDATA_OUT_PATH = './data/'\nINPUT_TRAIN_DATA = 'nsmc_train_input.npy'\nLABEL_TRAIN_DATA = 'nsmc_train_label.npy'\nDATA_CONFIGS = 'data_configs.json'\n\ninput_data = np.load(open(DATA_IN_PATH + INPUT_TRAIN_DATA, 'rb'))\nlabel_data = np.load(open(DATA_IN_PATH + LABEL_TRAIN_DATA, 'rb'))\nprepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "TEST_SPLIT = 0.1\nRNG_SEED = 13371447\nVOCAB_SIZE = prepro_configs['vocab_size']\nEMB_SIZE = 128\nBATCH_SIZE = 16\nNUM_EPOCHS = 1\n\ninput_train, input_eval, label_train, label_eval = train_test_split(input_data, label_data, test_size=TEST_SPLIT, random_state=RNG_SEED)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def mapping_fn(X, Y):\n    input, label = {'x': X}, Y\n    return input, label\n\ndef train_input_fn():\n    dataset = tf.data.Dataset.from_tensor_slices((input_train, label_train))\n    dataset = dataset.shuffle(buffer_size=len(input_train))\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.map(mapping_fn)\n    dataset = dataset.repeat(count=NUM_EPOCHS)\n    iterator = dataset.make_one_shot_iterator()\n    \n    return iterator.get_next()\n\ndef eval_input_fn():\n    dataset = tf.data.Dataset.from_tensor_slices((input_eval, label_eval))\n    dataset = dataset.shuffle(buffer_size=len(input_eval))\n    dataset = dataset.batch(16)\n    dataset = dataset.map(mapping_fn)\n    iterator = dataset.make_one_shot_iterator()\n    \n    return iterator.get_next()",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def model_fn(features, labels, mode, params):\n    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n    EVAL = mode == tf.estimator.ModeKeys.EVAL\n    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n\n    embedding_layer = tf.keras.layers.Embedding(\n                    VOCAB_SIZE + 1,\n                    EMB_SIZE)(features['x'])\n\n    dropout_emb = tf.keras.layers.Dropout(rate = 0.2)(embedding_layer)\n    \n    conv = tf.layers.conv1d(\n           inputs=dropout_emb,\n           filters=32,\n           kernel_size=3,\n           padding='same',\n           activation=tf.nn.relu)\n  \n    pool = tf.keras.layers.GlobalMaxPool1D()(conv)\n\n    hidden = tf.keras.layers.Dense(units=250, activation=tf.nn.relu)(pool)   \n\n\n    dropout_hidden = tf.keras.layers.Dropout(rate=0.2)(hidden, training = TRAIN)\n    logits = tf.keras.layers.Dense(units=1)(dropout_hidden)\n\n    if labels is not None:\n        labels = tf.reshape(labels, [-1, 1])\n        \n    if TRAIN:\n        global_step = tf.train.get_global_step()\n        loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n        train_op = tf.train.AdamOptimizer(0.001).minimize(loss, global_step)\n\n        return tf.estimator.EstimatorSpec(mode=mode, train_op=train_op, loss = loss)\n    \n    elif EVAL:\n        loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n        pred = tf.nn.sigmoid(logits)\n        accuracy = tf.metrics.accuracy(labels, tf.round(pred))\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops={'acc': accuracy})\n        \n    elif PREDICT:\n        return tf.estimator.EstimatorSpec(\n            mode=mode,\n            predictions={\n                'prob': tf.nn.sigmoid(logits),\n            }\n        )",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "est = tf.estimator.Estimator(model_fn, model_dir=\"data/checkpoint/cnn_model\")",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "INFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': 'data/checkpoint/cnn_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f69a406e240>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\nWARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f69b17107b8>) includes params argument, but params are not passed to Estimator.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "time_start = datetime.utcnow()\nprint(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\nprint(\".......................................\") \n\nest.train(train_input_fn)\n\ntime_end = datetime.utcnow()\nprint(\".......................................\")\nprint(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\nprint(\"\")\ntime_elapsed = time_end - time_start\nprint(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Experiment started at 02:16:56\n.......................................\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 0 into data/checkpoint/cnn_model/model.ckpt.\nINFO:tensorflow:loss = 0.68810225, step = 1\nINFO:tensorflow:global_step/sec: 36.0173\nINFO:tensorflow:loss = 0.4824096, step = 101 (2.781 sec)\nINFO:tensorflow:global_step/sec: 40.0906\nINFO:tensorflow:loss = 0.09750176, step = 201 (2.496 sec)\nINFO:tensorflow:global_step/sec: 52.5717\nINFO:tensorflow:loss = 0.63134986, step = 301 (1.907 sec)\nINFO:tensorflow:global_step/sec: 59.951\nINFO:tensorflow:loss = 0.23599344, step = 401 (1.658 sec)\nINFO:tensorflow:global_step/sec: 85.8338\nINFO:tensorflow:loss = 0.15393466, step = 501 (1.169 sec)\nINFO:tensorflow:global_step/sec: 76.1902\nINFO:tensorflow:loss = 0.21929471, step = 601 (1.312 sec)\nINFO:tensorflow:global_step/sec: 80.5764\nINFO:tensorflow:loss = 0.25892052, step = 701 (1.239 sec)\nINFO:tensorflow:global_step/sec: 61.0929\nINFO:tensorflow:loss = 0.15670818, step = 801 (1.641 sec)\nINFO:tensorflow:global_step/sec: 71.6512\nINFO:tensorflow:loss = 0.45960844, step = 901 (1.390 sec)\nINFO:tensorflow:global_step/sec: 60.6299\nINFO:tensorflow:loss = 0.25304508, step = 1001 (1.653 sec)\nINFO:tensorflow:global_step/sec: 74.9615\nINFO:tensorflow:loss = 0.24114716, step = 1101 (1.331 sec)\nINFO:tensorflow:global_step/sec: 93.0021\nINFO:tensorflow:loss = 0.39978263, step = 1201 (1.078 sec)\nINFO:tensorflow:global_step/sec: 85.7913\nINFO:tensorflow:loss = 0.15252419, step = 1301 (1.166 sec)\nINFO:tensorflow:global_step/sec: 57.5482\nINFO:tensorflow:loss = 0.28669545, step = 1401 (1.737 sec)\nINFO:tensorflow:global_step/sec: 62.1768\nINFO:tensorflow:loss = 0.2660273, step = 1501 (1.607 sec)\nINFO:tensorflow:global_step/sec: 62.3845\nINFO:tensorflow:loss = 0.11482005, step = 1601 (1.604 sec)\nINFO:tensorflow:global_step/sec: 72.0797\nINFO:tensorflow:loss = 0.2019555, step = 1701 (1.388 sec)\nINFO:tensorflow:global_step/sec: 86.2214\nINFO:tensorflow:loss = 0.3242884, step = 1801 (1.157 sec)\nINFO:tensorflow:global_step/sec: 69.0985\nINFO:tensorflow:loss = 0.56442827, step = 1901 (1.454 sec)\nINFO:tensorflow:global_step/sec: 50.0321\nINFO:tensorflow:loss = 0.06166517, step = 2001 (1.993 sec)\nINFO:tensorflow:global_step/sec: 79.1703\nINFO:tensorflow:loss = 0.5452158, step = 2101 (1.265 sec)\nINFO:tensorflow:global_step/sec: 58.4216\nINFO:tensorflow:loss = -0.2925219, step = 2201 (1.708 sec)\nINFO:tensorflow:global_step/sec: 42.3663\nINFO:tensorflow:loss = 0.063866094, step = 2301 (2.363 sec)\nINFO:tensorflow:global_step/sec: 77.7944\nINFO:tensorflow:loss = 0.6434481, step = 2401 (1.284 sec)\nINFO:tensorflow:global_step/sec: 56.822\nINFO:tensorflow:loss = 0.12014991, step = 2501 (1.764 sec)\nINFO:tensorflow:global_step/sec: 84.8036\nINFO:tensorflow:loss = 0.60028285, step = 2601 (1.176 sec)\nINFO:tensorflow:global_step/sec: 59.9242\nINFO:tensorflow:loss = 0.3053768, step = 2701 (1.667 sec)\nINFO:tensorflow:global_step/sec: 56.097\nINFO:tensorflow:loss = 0.053589337, step = 2801 (1.798 sec)\nINFO:tensorflow:global_step/sec: 49.064\nINFO:tensorflow:loss = 0.09301191, step = 2901 (2.024 sec)\nINFO:tensorflow:global_step/sec: 65.4933\nINFO:tensorflow:loss = 0.6538961, step = 3001 (1.532 sec)\nINFO:tensorflow:global_step/sec: 50.4569\nINFO:tensorflow:loss = 0.67301726, step = 3101 (1.981 sec)\nINFO:tensorflow:global_step/sec: 46.6919\nINFO:tensorflow:loss = 2.1049242, step = 3201 (2.136 sec)\nINFO:tensorflow:global_step/sec: 70.4462\nINFO:tensorflow:loss = 0.115423456, step = 3301 (1.421 sec)\nINFO:tensorflow:global_step/sec: 67.1396\nINFO:tensorflow:loss = 1.4576322, step = 3401 (1.487 sec)\nINFO:tensorflow:global_step/sec: 56.0383\nINFO:tensorflow:loss = -12.835906, step = 3501 (1.787 sec)\nINFO:tensorflow:global_step/sec: 75.0344\nINFO:tensorflow:loss = -28.290012, step = 3601 (1.333 sec)\nINFO:tensorflow:global_step/sec: 62.4605\nINFO:tensorflow:loss = 28.374964, step = 3701 (1.601 sec)\nINFO:tensorflow:global_step/sec: 53.4055\nINFO:tensorflow:loss = -9.401832, step = 3801 (1.872 sec)\nINFO:tensorflow:global_step/sec: 73.1541\nINFO:tensorflow:loss = 0.8318301, step = 3901 (1.365 sec)\nINFO:tensorflow:global_step/sec: 66.2945\nINFO:tensorflow:loss = 0.08372137, step = 4001 (1.508 sec)\nINFO:tensorflow:global_step/sec: 46.57\nINFO:tensorflow:loss = 0.13218117, step = 4101 (2.150 sec)\nINFO:tensorflow:global_step/sec: 41.3841\nINFO:tensorflow:loss = 36.576145, step = 4201 (2.416 sec)\nINFO:tensorflow:global_step/sec: 59.0164\nINFO:tensorflow:loss = -116.100174, step = 4301 (1.695 sec)\nINFO:tensorflow:global_step/sec: 66.0937\nINFO:tensorflow:loss = 79.285385, step = 4401 (1.514 sec)\nINFO:tensorflow:global_step/sec: 61.1563\nINFO:tensorflow:loss = 40.636612, step = 4501 (1.632 sec)\nINFO:tensorflow:global_step/sec: 66.4884\nINFO:tensorflow:loss = 7.3596926, step = 4601 (1.505 sec)\nINFO:tensorflow:global_step/sec: 71.0108\nINFO:tensorflow:loss = 39.44811, step = 4701 (1.405 sec)\nINFO:tensorflow:global_step/sec: 80.1338\nINFO:tensorflow:loss = 303.45572, step = 4801 (1.252 sec)\nINFO:tensorflow:global_step/sec: 83.642\nINFO:tensorflow:loss = 128.79713, step = 4901 (1.193 sec)\nINFO:tensorflow:global_step/sec: 77.996\nINFO:tensorflow:loss = 0.30728078, step = 5001 (1.280 sec)\nINFO:tensorflow:global_step/sec: 79.9913\nINFO:tensorflow:loss = 20.08603, step = 5101 (1.252 sec)\nINFO:tensorflow:global_step/sec: 55.9055\nINFO:tensorflow:loss = 324.4765, step = 5201 (1.795 sec)\nINFO:tensorflow:global_step/sec: 83.4026\nINFO:tensorflow:loss = 0.13973401, step = 5301 (1.190 sec)\nINFO:tensorflow:global_step/sec: 59.8355\nINFO:tensorflow:loss = -105.861946, step = 5401 (1.676 sec)\nINFO:tensorflow:global_step/sec: 84.2609\nINFO:tensorflow:loss = 82.620964, step = 5501 (1.183 sec)\nINFO:tensorflow:global_step/sec: 62.3522\nINFO:tensorflow:loss = 1.1339164, step = 5601 (1.609 sec)\nINFO:tensorflow:global_step/sec: 46.8406\nINFO:tensorflow:loss = -674.29395, step = 5701 (2.141 sec)\nINFO:tensorflow:global_step/sec: 50.5708\nINFO:tensorflow:loss = -268.95633, step = 5801 (1.968 sec)\nINFO:tensorflow:global_step/sec: 56.3477\nINFO:tensorflow:loss = -269.01874, step = 5901 (1.774 sec)\nINFO:tensorflow:global_step/sec: 75.3149\nINFO:tensorflow:loss = -1044.8667, step = 6001 (1.327 sec)\nINFO:tensorflow:global_step/sec: 78.785\nINFO:tensorflow:loss = -148.3497, step = 6101 (1.267 sec)\nINFO:tensorflow:global_step/sec: 56.5161\nINFO:tensorflow:loss = -648.3357, step = 6201 (1.771 sec)\nINFO:tensorflow:global_step/sec: 58.8876\nINFO:tensorflow:loss = 0.39559883, step = 6301 (1.711 sec)\nINFO:tensorflow:global_step/sec: 51.0163\nINFO:tensorflow:loss = 514.8923, step = 6401 (1.951 sec)\nINFO:tensorflow:global_step/sec: 54.9504\nINFO:tensorflow:loss = 189.93869, step = 6501 (1.834 sec)\nINFO:tensorflow:global_step/sec: 64.7699\nINFO:tensorflow:loss = 52.436584, step = 6601 (1.534 sec)\nINFO:tensorflow:global_step/sec: 75.0846\nINFO:tensorflow:loss = 0.11522962, step = 6701 (1.326 sec)\nINFO:tensorflow:global_step/sec: 66.4091\nINFO:tensorflow:loss = 0.56325203, step = 6801 (1.505 sec)\nINFO:tensorflow:global_step/sec: 66.5049\nINFO:tensorflow:loss = -52.48702, step = 6901 (1.505 sec)\nINFO:tensorflow:global_step/sec: 65.385\nINFO:tensorflow:loss = 337.36258, step = 7001 (1.527 sec)\nINFO:tensorflow:global_step/sec: 60.6134\nINFO:tensorflow:loss = -466.4112, step = 7101 (1.650 sec)\nINFO:tensorflow:global_step/sec: 78.2435\nINFO:tensorflow:loss = 1324.2122, step = 7201 (1.280 sec)\nINFO:tensorflow:global_step/sec: 81.5332\nINFO:tensorflow:loss = 82.20009, step = 7301 (1.224 sec)\nINFO:tensorflow:global_step/sec: 55.6957\nINFO:tensorflow:loss = 2184.0107, step = 7401 (1.797 sec)\nINFO:tensorflow:global_step/sec: 51.3729\nINFO:tensorflow:loss = -4006.451, step = 7501 (1.949 sec)\nINFO:tensorflow:global_step/sec: 49.4106\nINFO:tensorflow:loss = -965.87866, step = 7601 (2.022 sec)\nINFO:tensorflow:global_step/sec: 47.8173\nINFO:tensorflow:loss = -869.2809, step = 7701 (2.091 sec)\nINFO:tensorflow:global_step/sec: 56.7192\nINFO:tensorflow:loss = 978.5914, step = 7801 (1.760 sec)\nINFO:tensorflow:global_step/sec: 80.2803\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "INFO:tensorflow:loss = 0.16489297, step = 7901 (1.248 sec)\nINFO:tensorflow:global_step/sec: 82.3864\nINFO:tensorflow:loss = 5.46847, step = 8001 (1.213 sec)\nINFO:tensorflow:global_step/sec: 83.0669\nINFO:tensorflow:loss = 0.1167956, step = 8101 (1.201 sec)\nINFO:tensorflow:global_step/sec: 52.4509\nINFO:tensorflow:loss = -2576.6685, step = 8201 (1.912 sec)\nINFO:tensorflow:global_step/sec: 68.1882\nINFO:tensorflow:loss = -849.2069, step = 8301 (1.461 sec)\nINFO:tensorflow:global_step/sec: 68.2396\nINFO:tensorflow:loss = 0.42143255, step = 8401 (1.469 sec)\nINFO:tensorflow:global_step/sec: 55.0109\nINFO:tensorflow:loss = 2779.6108, step = 8501 (1.813 sec)\nINFO:tensorflow:global_step/sec: 73.4446\nINFO:tensorflow:loss = 0.10283862, step = 8601 (1.362 sec)\nINFO:tensorflow:global_step/sec: 87.8382\nINFO:tensorflow:loss = -178.1823, step = 8701 (1.142 sec)\nINFO:tensorflow:global_step/sec: 89.8109\nINFO:tensorflow:loss = 0.09579904, step = 8801 (1.112 sec)\nINFO:tensorflow:global_step/sec: 60.6131\nINFO:tensorflow:loss = 0.3334053, step = 8901 (1.651 sec)\nINFO:tensorflow:global_step/sec: 78.9136\nINFO:tensorflow:loss = 775.7569, step = 9001 (1.266 sec)\nINFO:tensorflow:global_step/sec: 84.5497\nINFO:tensorflow:loss = -3711.9666, step = 9101 (1.185 sec)\nINFO:tensorflow:global_step/sec: 86.9352\nINFO:tensorflow:loss = 0.25345072, step = 9201 (1.149 sec)\nINFO:tensorflow:global_step/sec: 76.572\nINFO:tensorflow:loss = -4739.598, step = 9301 (1.306 sec)\nINFO:tensorflow:Saving checkpoints for 9400 into data/checkpoint/cnn_model/model.ckpt.\nINFO:tensorflow:Loss for final step: -1277.0737.\n.......................................\nExperiment finished at 02:20:53\n\nExperiment elapsed time: 236.458152 seconds\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pickle",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open('./data/tf_idf_model.pkl', 'wb') as f:\n    pickle.dump(est, f)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open('./data/tf_idf_model.pkl', 'rb') as f:\n    test = pickle.load(f)",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "<tensorflow.python.estimator.estimator.Estimator at 0x7f699c4c4c18>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open('./tf_idf_model.pkl', 'rb') as f:\n    ctest = pickle.load(f)",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ctest",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "Pipeline(memory=None,\n     steps=[('vect', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=0.0,\n        ngram_range=(1, 5), norm='l2', preprocessor=None, smooth_idf=True,\n...nalty='l2', random_state=0,\n          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "valid = est.evaluate(eval_input_fn)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "INFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2019-05-24-03:22:47\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from data/checkpoint/cnn_model/model.ckpt-9400\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Finished evaluation at 2019-05-24-03:22:52\nINFO:tensorflow:Saving dict for global step 9400: acc = 0.90742624, global_step = 9400, loss = -841.4986\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 9400: data/checkpoint/cnn_model/model.ckpt-9400\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "INPUT_TEST_DATA = 'nsmc_test_input.npy'\nLABEL_TEST_DATA = 'nsmc_test_label.npy'\n\ntest_input_data = np.load(open(DATA_IN_PATH + INPUT_TEST_DATA, 'rb'))\ntest_label_data = np.load(open(DATA_IN_PATH + LABEL_TEST_DATA, 'rb'))",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def test_input_fn():\n    dataset = tf.data.Dataset.from_tensor_slices((test_input_data, test_label_data))\n    dataset = dataset.batch(16)\n    dataset = dataset.map(mapping_fn)\n    iterator = dataset.make_one_shot_iterator()\n    \n    return iterator.get_next()",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "predict = est.evaluate(test_input_fn) ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "INFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2019-05-24-03:23:08\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from data/checkpoint/cnn_model/model.ckpt-9400\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Finished evaluation at 2019-05-24-03:23:33\nINFO:tensorflow:Saving dict for global step 9400: acc = 0.90574473, global_step = 9400, loss = -1424.6682\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 9400: data/checkpoint/cnn_model/model.ckpt-9400\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "predict",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "{'acc': 0.90574473, 'loss': -1424.6682, 'global_step': 9400}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def predict_pos_neg(review):\n    token = tokenize(review)\n    tf = term_frequency(token)\n    data = np.expand_dims(np.asarray(tf).astype('float32'), axis=0)\n    score = float(model.predict(data))\n    if(score > 0.5):\n        print(\"[{}]는 {:.2f}% 확률로 긍정 리뷰이지 않을까 추측해봅니다.^^\\n\".format(review, score * 100))\n    else:\n        print(\"[{}]는 {:.2f}% 확률로 부정 리뷰이지 않을까 추측해봅니다.^^;\\n\".format(review, (1 - score) * 100))",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def tokenize(doc):\n    # norm은 정규화, stem은 근어로 표시하기를 나타냄\n    return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def term_frequency(doc):\n    return [doc.count(word) for word in selected_words]",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from konlpy.tag import Okt\nokt = Okt()",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "predict_pos_neg(\"올해 최고의 영화! 세 번 넘게 봐도 질리지가 않네요.\")\npredict_pos_neg(\"배경 음악이 영화의 분위기랑 너무 안 맞았습니다. 몰입에 방해가 됩니다.\")\npredict_pos_neg(\"주연 배우가 신인인데 연기를 진짜 잘 하네요. 몰입감 ㅎㄷㄷ\")\npredict_pos_neg(\"믿고 보는 감독이지만 이번에는 아니네요\")\npredict_pos_neg(\"주연배우 때문에 봤어요\")",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'selected_words' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-50e33b377ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_pos_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"올해 최고의 영화! 세 번 넘게 봐도 질리지가 않네요.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredict_pos_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"배경 음악이 영화의 분위기랑 너무 안 맞았습니다. 몰입에 방해가 됩니다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredict_pos_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"주연 배우가 신인인데 연기를 진짜 잘 하네요. 몰입감 ㅎㄷㄷ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredict_pos_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"믿고 보는 감독이지만 이번에는 아니네요\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredict_pos_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"주연배우 때문에 봤어요\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-bc3e564b6097>\u001b[0m in \u001b[0;36mpredict_pos_neg\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_pos_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-87dc2f22185a>\u001b[0m in \u001b[0;36mterm_frequency\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'selected_words' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}